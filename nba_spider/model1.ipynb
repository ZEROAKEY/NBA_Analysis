{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('灰熊', 118, '热火', 120)\n",
      "('快船', 98, '灰熊', 99)\n",
      "('魔术', 100, '森林狼', 115)\n",
      "('勇士', 99, '热火', 102)\n",
      "('76人', 103, '凯尔特人', 98)\n",
      "('黄蜂', 97, '篮网', 90)\n",
      "('猛龙', 89, '马刺', 100)\n",
      "('活塞', 87, '爵士', 97)\n",
      "('火箭', 95, '开拓者', 105)\n",
      "('太阳', 77, '国王', 87)\n",
      "('雄鹿', 79, '奇才', 91)\n",
      "('步行者', 93, '骑士', 100)\n",
      "('尼克斯', 90, '老鹰', 82)\n",
      "('公牛', 81, '湖人', 107)\n",
      "('鹈鹕', 82, '掘金', 91)\n",
      "('雷霆', 88, '独行侠', 79)\n",
      "('雄鹿', 90, '太阳', 115)\n",
      "('独行侠', 101, '凯尔特人', 90)\n",
      "('老鹰', 99, '公牛', 103)\n",
      "('尼克斯', 91, '活塞', 90)\n",
      "('76人', 96, '马刺', 80)\n",
      "('猛龙', 73, '热火', 109)\n",
      "('勇士', 90, '雷霆', 83)\n",
      "('开拓者', 68, '黄蜂', 84)\n",
      "('步行者', 71, '掘金', 86)\n",
      "('灰熊', 88, '鹈鹕', 77)\n",
      "('奇才', 73, '国王', 69)\n",
      "('魔术', 100, '篮网', 102)\n",
      "('湖人', 93, '骑士', 89)\n",
      "('快船', 105, '爵士', 88)\n",
      "('森林狼', 93, '火箭', 83)\n",
      "('热火', 92, '独行侠', 79)\n",
      "('国王', 105, '尼克斯', 106)\n",
      "('猛龙', 76, '爵士', 86)\n",
      "('凯尔特人', 89, '黄蜂', 84)\n",
      "('灰熊', 104, '魔术', 98)\n",
      "('太阳', 100, '雷霆', 99)\n",
      "('湖人', 87, '老鹰', 86)\n",
      "('勇士', 96, '骑士', 85)\n",
      "('步行者', 98, '太阳', 94)\n",
      "('尼克斯', 85, '篮网', 92)\n",
      "('黄蜂', 80, '掘金', 66)\n",
      "('公牛', 77, '活塞', 85)\n",
      "('76人', 92, '森林狼', 90)\n",
      "('奇才', 80, '开拓者', 82)\n",
      "('快船', 112, '雄鹿', 97)\n",
      "('鹈鹕', 85, '马刺', 90)\n",
      "('雷霆', 73, '热火', 102)\n",
      "('活塞', 87, '火箭', 73)\n",
      "('独行侠', 88, '灰熊', 108)\n",
      "('开拓者', 97, '76人', 95)\n",
      "('爵士', 70, '国王', 82)\n",
      "('凯尔特人', 88, '湖人', 74)\n",
      "('骑士', 112, '雄鹿', 81)\n",
      "('篮网', 78, '快船', 87)\n",
      "('森林狼', 105, '步行者', 94)\n",
      "('火箭', 109, '奇才', 91)\n",
      "('魔术', 91, '鹈鹕', 86)\n",
      "('马刺', 79, '老鹰', 76)\n",
      "('掘金', 81, '猛龙', 84)\n",
      "('公牛', 82, '勇士', 92)\n",
      "('雄鹿', 89, '公牛', 96)\n",
      "('黄蜂', 94, '尼克斯', 90)\n",
      "('热火', 119, '凯尔特人', 114)\n",
      "('活塞', 81, '76人', 94)\n",
      "('雷霆', 69, '猛龙', 94)\n",
      "('马刺', 83, '开拓者', 77)\n",
      "('爵士', 90, '独行侠', 89)\n",
      "('太阳', 73, '勇士', 90)\n",
      "('骑士', 79, '魔术', 106)\n",
      "('鹈鹕', 74, '森林狼', 81)\n",
      "('国王', 83, '灰熊', 103)\n",
      "('火箭', 99, '湖人', 80)\n",
      "('篮网', 97, '步行者', 95)\n",
      "('老鹰', 88, '奇才', 94)\n",
      "('掘金', 78, '快船', 88)\n",
      "('热火', 80, '湖人', 76)\n",
      "('灰熊', 77, '雷霆', 80)\n",
      "('76人', 85, '爵士', 93)\n",
      "('国王蓝队', 90, '勇士', 91)\n",
      "('灰熊', 87, '76人', 85)\n",
      "('雷霆', 98, '爵士', 75)\n",
      "('黄蜂', 86, '国王红队', 82)\n",
      "('雷霆', 92, '76人', 102)\n",
      "('灰熊', 95, '爵士', 97)\n",
      "('热火', 102, '国王蓝队', 86)\n",
      "('湖人', 68, '勇士', 92)\n",
      "('马刺', 59, '国王红队', 85)\n",
      "('湖人', 94, '国王蓝队', 108)\n",
      "('热火', 66, '勇士', 105)\n",
      "('黄蜂', 97, '马刺', 65)\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from SQLiteDB import SQLiteDB\n",
    "# 中文队名映射\n",
    "team_name_mapping = {\n",
    "    '老鹰': '亚特兰大老鹰',\n",
    "    '凯尔特人': '波士顿凯尔特人',\n",
    "    '篮网': '布鲁克林篮网',\n",
    "    '黄蜂': '夏洛特黄蜂',\n",
    "    '公牛': '芝加哥公牛',\n",
    "    '骑士': '克利夫兰骑士',\n",
    "    '独行侠': '达拉斯独行侠',\n",
    "    '掘金': '丹佛掘金',\n",
    "    '活塞': '底特律活塞',\n",
    "    '勇士': '金州勇士',\n",
    "    '火箭': '休斯顿火箭',\n",
    "    '步行者': '印第安纳步行者',\n",
    "    '快船': '洛杉矶快船',\n",
    "    '湖人': '洛杉矶湖人',\n",
    "    '灰熊': '孟菲斯灰熊',\n",
    "    '热火': '迈阿密热火',\n",
    "    '雄鹿': '密尔沃基雄鹿',\n",
    "    '森林狼': '明尼苏达森林狼',\n",
    "    '鹈鹕': '新奥尔良鹈鹕',\n",
    "    '尼克斯': '纽约尼克斯',\n",
    "    '雷霆': '俄克拉荷马城雷霆',\n",
    "    '魔术': '奥兰多魔术',\n",
    "    '76人': '费城76人',\n",
    "    '太阳': '菲尼克斯太阳',\n",
    "    '开拓者': '波特兰开拓者',\n",
    "    '国王': '萨克拉门托国王',\n",
    "    '马刺': '圣安东尼奥马刺',\n",
    "    '猛龙': '多伦多猛龙',\n",
    "    '爵士': '犹他爵士',\n",
    "    '奇才': '华盛顿奇才'\n",
    "}\n",
    "\n",
    "# 连接 SQLite 数据库\n",
    "conn = sqlite3.connect('C:\\\\code\\\\Project\\\\nba_springbootbatis\\\\springbootbatis\\\\src\\\\main\\\\resources\\\\nba_total.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 查询比赛数据\n",
    "query = '''\n",
    "    SELECT leftName, leftGoal, rightName, rightGoal\n",
    "    FROM nba_schedule\n",
    "    WHERE leftGoal != 0 AND rightGoal != 0\n",
    "      AND leftName !='' AND rightName !='' \n",
    "      AND leftName != '中国男篮' AND rightName != '中国男篮'\n",
    "    ORDER BY date DESC\n",
    "'''\n",
    "games = cursor.execute(query).fetchall()\n",
    "\n",
    "for game in games:\n",
    "    print(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "没有可用的文本数据进行 OneHot 编码，检查数据来源。\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import sqlite3\n",
    "\n",
    "# 定义我们需要的数值特征的索引（假设所有的数值列都要保留）\n",
    "features_index = slice(2, -1)\n",
    "\n",
    "# OneHotEncoder 用于处理文本数据（球员名字和队伍名称）\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 连接到 SQLite 数据库\n",
    "db_path = 'C:\\\\code\\\\Project\\\\nba_springbootbatis\\\\springbootbatis\\\\src\\\\main\\\\resources\\\\nba_total.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 查询需要的数据\n",
    "query = '''\n",
    "    SELECT leftName, leftGoal, rightName, rightGoal\n",
    "    FROM nba_schedule\n",
    "    WHERE leftGoal != 0 AND rightGoal != 0\n",
    "      AND leftName != '' AND rightName != ''\n",
    "      AND leftName != '中国男篮' AND rightName != '中国男篮'\n",
    "    ORDER BY date DESC\n",
    "'''\n",
    "games = cursor.execute(query).fetchall()\n",
    "\n",
    "# 准备存放 X 和 y 的列表\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# 准备用于 OneHot 编码的文本数据（如球员名字和队伍名）\n",
    "text_data = []\n",
    "\n",
    "# 遍历每场比赛，使用映射找到 team_id，并查询 players_info 表中的数据\n",
    "for game in games:\n",
    "    left_name, left_goal, right_name, right_goal = game\n",
    "\n",
    "    # 查询左队的 team_id\n",
    "    cursor.execute(\"SELECT team_id FROM team_names WHERE team_name = ?\", (left_name,))\n",
    "    left_team_id = cursor.fetchone()\n",
    "\n",
    "    # 查询右队的 team_id\n",
    "    cursor.execute(\"SELECT team_id FROM team_names WHERE team_name = ?\", (right_name,))\n",
    "    right_team_id = cursor.fetchone()\n",
    "\n",
    "    # 如果找到 team_id，则查询 players_info 表中的数据\n",
    "    if left_team_id and right_team_id:\n",
    "        # 查询左队的球员信息，并将空值替换为 0\n",
    "        cursor.execute(\"SELECT * FROM players_info WHERE team_id = ?\", (left_team_id[0],))\n",
    "        left_team_players = cursor.fetchall()\n",
    "        left_team_players = [[0 if val is None else val for val in player] for player in left_team_players]\n",
    "\n",
    "        # 查询右队的球员信息，并将空值替换为 0\n",
    "        cursor.execute(\"SELECT * FROM players_info WHERE team_id = ?\", (right_team_id[0],))\n",
    "        right_team_players = cursor.fetchall()\n",
    "        right_team_players = [[0 if val is None else val for val in player] for player in right_team_players]\n",
    "\n",
    "        # 提取左队和右队的数值特征\n",
    "        left_team_data = np.array([player[features_index] for player in left_team_players])\n",
    "        right_team_data = np.array([player[features_index] for player in right_team_players])\n",
    "\n",
    "        # 提取左队和右队的文本特征（如球员名字）\n",
    "        left_team_names = [player[1] for player in left_team_players]  # 假设 player[1] 是球员名字\n",
    "        right_team_names = [player[1] for player in right_team_players]\n",
    "\n",
    "        # 将文本特征添加到文本数据列表中，稍后用于 OneHot 编码\n",
    "        text_data.append(left_team_names + right_team_names)\n",
    "\n",
    "        # 合并左右队的数值数据\n",
    "        combined_team_data = np.hstack((left_team_data.flatten(), right_team_data.flatten()))\n",
    "        print('test',combined_team_data)\n",
    "        X.append(combined_team_data)\n",
    "\n",
    "        # 将 leftGoal 和 rightGoal 作为 y 的输出\n",
    "        y.append([left_goal, right_goal])\n",
    "\n",
    "# 转换 X 和 y 为 NumPy 数组\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# 对文本特征进行 OneHot 编码\n",
    "if len(text_data) > 0:\n",
    "    flat_text_data = np.array([item for sublist in text_data for item in sublist]).reshape(-1, 1)\n",
    "    onehot_encoded_text = onehot_encoder.fit_transform(flat_text_data)\n",
    "\n",
    "    # 将 OneHot 编码结果与数值特征合并\n",
    "    X_combined = np.hstack((X, onehot_encoded_text))\n",
    "\n",
    "    # 对 X_combined 进行标准化处理\n",
    "    X_scaled = scaler.fit_transform(X_combined)\n",
    "\n",
    "    # 输出数据维度信息\n",
    "    print(f\"输入数据 X 的维度: {X_scaled.shape}\")\n",
    "    print(f\"输出数据 y 的维度: {y.shape}\")\n",
    "else:\n",
    "    print(\"没有可用的文本数据进行 OneHot 编码，检查数据来源。\")\n",
    "\n",
    "# 断开数据库连接\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 X 和 y 转换为 NumPy 数组\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# 对 X 进行标准化处理\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 输出数据维度信息\n",
    "print(f\"输入数据 X 的维度: {X_scaled.shape}\")\n",
    "print(f\"输出数据 y 的维度: {y.shape}\")\n",
    "\n",
    "# 断开数据库连接\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.3155 - val_loss: 1.3980\n",
      "Epoch 2/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3219 - val_loss: 1.3478\n",
      "Epoch 3/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2989 - val_loss: 1.3040\n",
      "Epoch 4/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2452 - val_loss: 1.2732\n",
      "Epoch 5/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0787 - val_loss: 1.2492\n",
      "Epoch 6/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9899 - val_loss: 1.2279\n",
      "Epoch 7/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8852 - val_loss: 1.1993\n",
      "Epoch 8/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9619 - val_loss: 1.1836\n",
      "Epoch 9/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9215 - val_loss: 1.1754\n",
      "Epoch 10/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8110 - val_loss: 1.1632\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "预测结果： [[82.8884  91.62527]\n",
      " [89.70219 83.62048]\n",
      " [90.3509  96.37128]\n",
      " [89.82402 89.80915]\n",
      " [87.57904 86.39254]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 对 X 进行标准化\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "# 对 y 进行标准化\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "# 切分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建神经网络模型\n",
    "model = Sequential()\n",
    "\n",
    "# 第一层：输入层到第一个隐藏层，带有 10 个神经元，激活函数为 ReLU\n",
    "model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
    "\n",
    "# 第二层：第一个隐藏层到第二个隐藏层，带有 5 个神经元，激活函数为 ReLU\n",
    "model.add(Dense(5, activation='relu'))\n",
    "\n",
    "# 第三层：第二个隐藏层到输出层，带有 2 个神经元，用于回归任务（输出为连续值）\n",
    "model.add(Dense(2))\n",
    "\n",
    "# 编译模型，使用均方误差 (MSE) 作为损失函数，Adam 作为优化器\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=6, validation_data=(X_test, y_test))\n",
    "\n",
    "# 进行预测\n",
    "y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "# 将预测值反标准化，恢复到原始的尺度\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# 输出预测结果\n",
    "print(\"预测结果：\", y_pred[:5])  # 打印前5个预测结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">392</span> (1.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m392\u001b[0m (1.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> (520.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m130\u001b[0m (520.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">262</span> (1.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m262\u001b[0m (1.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
