{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('灰熊', 118, '热火', 120)\n",
      "('快船', 98, '灰熊', 99)\n",
      "('魔术', 100, '森林狼', 115)\n",
      "('勇士', 99, '热火', 102)\n",
      "('76人', 103, '凯尔特人', 98)\n",
      "('黄蜂', 97, '篮网', 90)\n",
      "('猛龙', 89, '马刺', 100)\n",
      "('活塞', 87, '爵士', 97)\n",
      "('火箭', 95, '开拓者', 105)\n",
      "('太阳', 77, '国王', 87)\n",
      "('雄鹿', 79, '奇才', 91)\n",
      "('步行者', 93, '骑士', 100)\n",
      "('尼克斯', 90, '老鹰', 82)\n",
      "('公牛', 81, '湖人', 107)\n",
      "('鹈鹕', 82, '掘金', 91)\n",
      "('雷霆', 88, '独行侠', 79)\n",
      "('雄鹿', 90, '太阳', 115)\n",
      "('独行侠', 101, '凯尔特人', 90)\n",
      "('老鹰', 99, '公牛', 103)\n",
      "('尼克斯', 91, '活塞', 90)\n",
      "('76人', 96, '马刺', 80)\n",
      "('猛龙', 73, '热火', 109)\n",
      "('勇士', 90, '雷霆', 83)\n",
      "('开拓者', 68, '黄蜂', 84)\n",
      "('步行者', 71, '掘金', 86)\n",
      "('灰熊', 88, '鹈鹕', 77)\n",
      "('奇才', 73, '国王', 69)\n",
      "('魔术', 100, '篮网', 102)\n",
      "('湖人', 93, '骑士', 89)\n",
      "('快船', 105, '爵士', 88)\n",
      "('森林狼', 93, '火箭', 83)\n",
      "('热火', 92, '独行侠', 79)\n",
      "('国王', 105, '尼克斯', 106)\n",
      "('猛龙', 76, '爵士', 86)\n",
      "('凯尔特人', 89, '黄蜂', 84)\n",
      "('灰熊', 104, '魔术', 98)\n",
      "('太阳', 100, '雷霆', 99)\n",
      "('湖人', 87, '老鹰', 86)\n",
      "('勇士', 96, '骑士', 85)\n",
      "('步行者', 98, '太阳', 94)\n",
      "('尼克斯', 85, '篮网', 92)\n",
      "('黄蜂', 80, '掘金', 66)\n",
      "('公牛', 77, '活塞', 85)\n",
      "('76人', 92, '森林狼', 90)\n",
      "('奇才', 80, '开拓者', 82)\n",
      "('快船', 112, '雄鹿', 97)\n",
      "('鹈鹕', 85, '马刺', 90)\n",
      "('雷霆', 73, '热火', 102)\n",
      "('活塞', 87, '火箭', 73)\n",
      "('独行侠', 88, '灰熊', 108)\n",
      "('开拓者', 97, '76人', 95)\n",
      "('爵士', 70, '国王', 82)\n",
      "('凯尔特人', 88, '湖人', 74)\n",
      "('骑士', 112, '雄鹿', 81)\n",
      "('篮网', 78, '快船', 87)\n",
      "('森林狼', 105, '步行者', 94)\n",
      "('火箭', 109, '奇才', 91)\n",
      "('魔术', 91, '鹈鹕', 86)\n",
      "('马刺', 79, '老鹰', 76)\n",
      "('掘金', 81, '猛龙', 84)\n",
      "('公牛', 82, '勇士', 92)\n",
      "('雄鹿', 89, '公牛', 96)\n",
      "('黄蜂', 94, '尼克斯', 90)\n",
      "('热火', 119, '凯尔特人', 114)\n",
      "('活塞', 81, '76人', 94)\n",
      "('雷霆', 69, '猛龙', 94)\n",
      "('马刺', 83, '开拓者', 77)\n",
      "('爵士', 90, '独行侠', 89)\n",
      "('太阳', 73, '勇士', 90)\n",
      "('骑士', 79, '魔术', 106)\n",
      "('鹈鹕', 74, '森林狼', 81)\n",
      "('国王', 83, '灰熊', 103)\n",
      "('火箭', 99, '湖人', 80)\n",
      "('篮网', 97, '步行者', 95)\n",
      "('老鹰', 88, '奇才', 94)\n",
      "('掘金', 78, '快船', 88)\n",
      "('热火', 80, '湖人', 76)\n",
      "('灰熊', 77, '雷霆', 80)\n",
      "('76人', 85, '爵士', 93)\n",
      "('国王蓝队', 90, '勇士', 91)\n",
      "('灰熊', 87, '76人', 85)\n",
      "('雷霆', 98, '爵士', 75)\n",
      "('黄蜂', 86, '国王红队', 82)\n",
      "('雷霆', 92, '76人', 102)\n",
      "('灰熊', 95, '爵士', 97)\n",
      "('热火', 102, '国王蓝队', 86)\n",
      "('湖人', 68, '勇士', 92)\n",
      "('马刺', 59, '国王红队', 85)\n",
      "('湖人', 94, '国王蓝队', 108)\n",
      "('热火', 66, '勇士', 105)\n",
      "('黄蜂', 97, '马刺', 65)\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from SQLiteDB import SQLiteDB\n",
    "# 中文队名映射\n",
    "team_name_mapping = {\n",
    "    '老鹰': '亚特兰大老鹰',\n",
    "    '凯尔特人': '波士顿凯尔特人',\n",
    "    '篮网': '布鲁克林篮网',\n",
    "    '黄蜂': '夏洛特黄蜂',\n",
    "    '公牛': '芝加哥公牛',\n",
    "    '骑士': '克利夫兰骑士',\n",
    "    '独行侠': '达拉斯独行侠',\n",
    "    '掘金': '丹佛掘金',\n",
    "    '活塞': '底特律活塞',\n",
    "    '勇士': '金州勇士',\n",
    "    '火箭': '休斯顿火箭',\n",
    "    '步行者': '印第安纳步行者',\n",
    "    '快船': '洛杉矶快船',\n",
    "    '湖人': '洛杉矶湖人',\n",
    "    '灰熊': '孟菲斯灰熊',\n",
    "    '热火': '迈阿密热火',\n",
    "    '雄鹿': '密尔沃基雄鹿',\n",
    "    '森林狼': '明尼苏达森林狼',\n",
    "    '鹈鹕': '新奥尔良鹈鹕',\n",
    "    '尼克斯': '纽约尼克斯',\n",
    "    '雷霆': '俄克拉荷马城雷霆',\n",
    "    '魔术': '奥兰多魔术',\n",
    "    '76人': '费城76人',\n",
    "    '太阳': '菲尼克斯太阳',\n",
    "    '开拓者': '波特兰开拓者',\n",
    "    '国王': '萨克拉门托国王',\n",
    "    '马刺': '圣安东尼奥马刺',\n",
    "    '猛龙': '多伦多猛龙',\n",
    "    '爵士': '犹他爵士',\n",
    "    '奇才': '华盛顿奇才'\n",
    "}\n",
    "\n",
    "# 连接 SQLite 数据库\n",
    "conn = sqlite3.connect('C:\\\\code\\\\Project\\\\nba_springbootbatis\\\\springbootbatis\\\\src\\\\main\\\\resources\\\\nba_total.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 查询比赛数据\n",
    "query = '''\n",
    "    SELECT leftName, leftGoal, rightName, rightGoal\n",
    "    FROM nba_schedule\n",
    "    WHERE leftGoal != 0 AND rightGoal != 0\n",
    "      AND leftName !='' AND rightName !='' \n",
    "      AND leftName != '中国男篮' AND rightName != '中国男篮'\n",
    "    ORDER BY date DESC\n",
    "'''\n",
    "games = cursor.execute(query).fetchall()\n",
    "\n",
    "for game in games:\n",
    "    print(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0            1            2         3           4            5  \\\n",
      "0  147.5  2010.724490  2011.680272  1.877551   81.176871  1901.068027   \n",
      "1  244.0  1998.334702  1999.425051  1.909651   90.642710  2160.683778   \n",
      "2  142.5  2007.323944  2008.588028  2.154930  101.404930  2383.714789   \n",
      "3  278.5  1989.010791  1990.370504  2.185252  109.559353  2520.771583   \n",
      "4  284.5  1994.000000  1995.352113  2.130282  103.237676  2472.250000   \n",
      "\n",
      "            6            7          8           9  ...        50        51  \\\n",
      "0  292.476190   648.292517  52.414966  150.482993  ...  0.238526  0.668052   \n",
      "1  355.977413   767.568789  39.330595  111.535934  ...  0.233439  0.641952   \n",
      "2  373.841549   821.250000  70.070423  198.341549  ...  0.226575  0.670735   \n",
      "3  444.516187  1002.723022  41.032374  113.388489  ...  0.238526  0.668052   \n",
      "4  413.158451   923.684859  31.204225   90.705986  ...  0.139231  0.662759   \n",
      "\n",
      "          52        53        54        55        56        57  left_goal  \\\n",
      "0  17.810727  6.459862  2.910035  1.461938  0.563668  0.305190        118   \n",
      "1  17.184014  6.156122  2.763265  1.517007  0.590476  0.305442         98   \n",
      "2  16.843537  6.338095  2.735714  1.576190  0.544898  0.337755        100   \n",
      "3  17.810727  6.459862  2.910035  1.461938  0.563668  0.305190         99   \n",
      "4  13.607961  5.930874  2.587379  1.354757  0.373398  0.215728        103   \n",
      "\n",
      "   right_goal  \n",
      "0         120  \n",
      "1          99  \n",
      "2         115  \n",
      "3         102  \n",
      "4          98  \n",
      "\n",
      "[5 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sqlite3\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 连接到 SQLite 数据库\n",
    "db_path = 'C:\\\\code\\\\Project\\\\nba_springbootbatis\\\\springbootbatis\\\\src\\\\main\\\\resources\\\\nba_total.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 查询需要的数据\n",
    "query = '''\n",
    "    SELECT leftName, leftGoal, rightName, rightGoal\n",
    "    FROM nba_schedule\n",
    "    WHERE leftGoal != 0 AND rightGoal != 0\n",
    "      AND leftName != '' AND rightName != ''\n",
    "      AND leftName != '中国男篮' AND rightName != '中国男篮'\n",
    "    ORDER BY date DESC\n",
    "'''\n",
    "games = cursor.execute(query).fetchall()\n",
    "\n",
    "# 准备存放 X 和 y 的列表\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# 遍历每场比赛，使用映射找到 team_id，并查询 players_info 表中的数据\n",
    "for game in games:\n",
    "    left_name, left_goal, right_name, right_goal = game\n",
    "\n",
    "    # 在查询队伍信息时，使用映射来转换 team_name\n",
    "    left_full_name = team_name_mapping.get(left_name, left_name)\n",
    "    right_full_name = team_name_mapping.get(right_name, right_name)\n",
    "\n",
    "    # 查询左队的 team_id\n",
    "    cursor.execute(\"SELECT team_id FROM team_names WHERE team_name = ?\", (left_full_name,))\n",
    "    left_team_id = cursor.fetchone()\n",
    "\n",
    "    # 查询右队的 team_id\n",
    "    cursor.execute(\"SELECT team_id FROM team_names WHERE team_name = ?\", (right_full_name,))\n",
    "    right_team_id = cursor.fetchone()\n",
    "\n",
    "    # 如果找到 team_id，则查询 players_info 表中的数据\n",
    "    if left_team_id and right_team_id:\n",
    "        # 查询左队的球员信息，并将空值替换为 0\n",
    "        cursor.execute(\"SELECT * FROM players_info WHERE team_id = ?\", (left_team_id[0],))\n",
    "        left_team_players = cursor.fetchall()\n",
    "        left_team_players = [[0 if val is None or val == '' else val for val in player] for player in left_team_players]\n",
    "\n",
    "        # 查询右队的球员信息，并将空值和空字符串替换为 0\n",
    "        cursor.execute(\"SELECT * FROM players_info WHERE team_id = ?\", (right_team_id[0],))\n",
    "        right_team_players = cursor.fetchall()\n",
    "        right_team_players = [[0 if val is None or val == '' else val for val in player] for player in right_team_players]\n",
    "\n",
    "        # 定义需要转换为浮点数的列索引\n",
    "        numeric_columns_indices = [\n",
    "            0,2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
    "            23, 24, 25, 26, 27, 28, 29\n",
    "        ]  # 跳过 player_name, team_name 和 team_id\n",
    "\n",
    "        # 转换左队数值数据\n",
    "        left_team_data = np.array(left_team_players)[:, numeric_columns_indices]\n",
    "        \n",
    "        left_team_data = left_team_data.astype(np.float64)\n",
    "\n",
    "        # 转换右队数值数据\n",
    "        right_team_data = np.array(right_team_players)[:, numeric_columns_indices]\n",
    "        right_team_data = right_team_data.astype(np.float64)\n",
    "\n",
    "        # 计算左右队的数值特征的均值\n",
    "        left_team_avg = np.mean(left_team_data, axis=0)\n",
    "        right_team_avg = np.mean(right_team_data, axis=0)\n",
    "\n",
    "        # 合并左右队的均值特征数据\n",
    "        combined_team_data = np.hstack((left_team_avg, right_team_avg))\n",
    "        X.append(combined_team_data)\n",
    "\n",
    "        # 将 leftGoal 和 rightGoal 作为 y 的输出\n",
    "        y.append([left_goal, right_goal])\n",
    "\n",
    "# 转换为 DataFrame\n",
    "df_X = pd.DataFrame(X)\n",
    "df_y = pd.DataFrame(y, columns=['left_goal', 'right_goal'])\n",
    "\n",
    "# 合并 X 和 y\n",
    "df_combined = pd.concat([df_X, df_y], axis=1)\n",
    "\n",
    "# 删除所有全为 None 或 NaN 的列，并将剩余的 NaN 值替换为 0\n",
    "df_combined_cleaned = df_combined.dropna(axis=1, how='all').fillna(0)\n",
    "\n",
    "# 打印前几行结果\n",
    "print(df_combined_cleaned.head())\n",
    "\n",
    "# 断开数据库连接\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对 X 进行标准化\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "# 对 y 进行标准化\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.1885205 ,  1.56067339,  1.5382903 , ..., -0.29118723,\n",
       "         1.31747616,  0.70643394],\n",
       "       [ 0.6611807 , -0.17065393, -0.20144675, ...,  0.37437706,\n",
       "         1.76563117,  0.71335261],\n",
       "       [-1.28435994,  1.085487  ,  1.09931891, ...,  1.0896702 ,\n",
       "         1.00370076,  1.60097864],\n",
       "       ...,\n",
       "       [ 0.73785225, -1.07617975, -1.05560896, ...,  0.3731645 ,\n",
       "        -0.82023202, -1.15546822],\n",
       "       [-1.23644022,  0.94786671,  0.97310809, ...,  0.3731645 ,\n",
       "        -0.82023202, -1.15546822],\n",
       "       [-1.15018472,  0.932368  ,  0.93343075, ..., -1.38167192,\n",
       "        -1.20592735, -0.31565431]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (86,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 转换 X 和 y 为 NumPy 数组\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X)\n\u001b[0;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 对文本特征进行 OneHot 编码\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (86,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# 转换 X 和 y 为 NumPy 数组\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# 对文本特征进行 OneHot 编码\n",
    "if len(text_data) > 0:\n",
    "    flat_text_data = np.array([item for sublist in text_data for item in sublist]).reshape(-1, 1)\n",
    "    onehot_encoded_text = onehot_encoder.fit_transform(flat_text_data)\n",
    "\n",
    "    # 将 OneHot 编码结果与数值特征合并\n",
    "    X_combined = np.hstack((X, onehot_encoded_text))\n",
    "\n",
    "    # 对 X_combined 进行标准化处理\n",
    "    X_scaled = scaler.fit_transform(X_combined)\n",
    "\n",
    "    # 输出数据维度信息\n",
    "    print(f\"输入数据 X 的维度: {X_scaled.shape}\")\n",
    "    print(f\"输出数据 y 的维度: {y.shape}\")\n",
    "else:\n",
    "    print(\"没有可用的文本数据进行 OneHot 编码，检查数据来源。\")\n",
    "\n",
    "# 断开数据库连接\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.5638 - val_loss: 1.3327\n",
      "Epoch 2/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3086 - val_loss: 1.2409\n",
      "Epoch 3/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1513 - val_loss: 1.1635\n",
      "Epoch 4/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1358 - val_loss: 1.1114\n",
      "Epoch 5/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0033 - val_loss: 1.0718\n",
      "Epoch 6/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1538 - val_loss: 1.0496\n",
      "Epoch 7/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0279 - val_loss: 1.0302\n",
      "Epoch 8/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8551 - val_loss: 1.0112\n",
      "Epoch 9/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9360 - val_loss: 1.0015\n",
      "Epoch 10/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9457 - val_loss: 0.9977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "预测结果： [[81.228065 93.07676 ]\n",
      " [88.8723   93.26527 ]\n",
      " [87.48611  95.95641 ]\n",
      " [95.68552  94.22981 ]\n",
      " [85.02244  93.77476 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 对 X 进行标准化\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "# 对 y 进行标准化\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "# 切分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# 构建神经网络模型\n",
    "model = Sequential()\n",
    "\n",
    "# 第一层：输入层到第一个隐藏层，带有 10 个神经元，激活函数为 ReLU\n",
    "model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
    "\n",
    "# 第二层：第一个隐藏层到第二个隐藏层，带有 5 个神经元，激活函数为 ReLU\n",
    "model.add(Dense(5, activation='relu'))\n",
    "\n",
    "# 第三层：第二个隐藏层到输出层，带有 2 个神经元，用于回归任务（输出为连续值）\n",
    "model.add(Dense(2))\n",
    "\n",
    "# 编译模型，使用均方误差 (MSE) 作为损失函数，Adam 作为优化器\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=6, validation_data=(X_test, y_test))\n",
    "\n",
    "# 进行预测\n",
    "y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "# 将预测值反标准化，恢复到原始的尺度\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# 输出预测结果\n",
    "print(\"预测结果：\", y_pred[:5])  # 打印前5个预测结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">590</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m590\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m55\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m12\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,973</span> (7.71 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,973\u001b[0m (7.71 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">657</span> (2.57 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m657\u001b[0m (2.57 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,316</span> (5.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,316\u001b[0m (5.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已保存。\n"
     ]
    }
   ],
   "source": [
    "# 保存模型到文件\n",
    "model.save('nba_score_prediction_model.h5')\n",
    "print(\"模型已保存。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已加载。\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "从加载的模型中获得的预测结果： [[81. 93.]\n",
      " [89. 93.]\n",
      " [87. 96.]\n",
      " [96. 94.]\n",
      " [85. 94.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 读取模型，不进行编译\n",
    "loaded_model = load_model('nba_score_prediction_model.h5', compile=False)\n",
    "print(\"模型已加载。\")\n",
    "\n",
    "# 手动编译模型，指定损失函数为 'mse'\n",
    "loaded_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# 使用加载的模型进行预测\n",
    "y_pred_loaded_model = loaded_model.predict(X_test)\n",
    "\n",
    "# 将预测值反标准化并取整\n",
    "y_pred_loaded_rounded = np.round(scaler_y.inverse_transform(y_pred_loaded_model))\n",
    "\n",
    "# 输出预测结果\n",
    "print(\"从加载的模型中获得的预测结果：\", y_pred_loaded_rounded[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler 已保存为 scaler_X.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# 假设 scaler_X 是你要保存的 StandardScaler 对象\n",
    "joblib.dump(scaler_y, 'scaler_y.pkl')\n",
    "print(\"StandardScaler 已保存为 scaler_X.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
